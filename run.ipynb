{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "a = input()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import pandas as pd\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import os\n",
    "\n",
    "\n",
    "import util as tu\n",
    "import model as tm\n",
    "from setup import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Args object at 0x000002871D5E8C70>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Args:\n",
    "    test_database_ids = [13]\n",
    "    random_seed = 114514\n",
    "    batch_size = 1000\n",
    "    accelerator = 'cpu'\n",
    "    progress_bar = True\n",
    "    lr = 0.001\n",
    "    epochs = 200\n",
    "    clip_size = 50\n",
    "    embed_size = 64\n",
    "    pred_hid = 128\n",
    "    ffn_dim = 128\n",
    "    head_size = 12\n",
    "    n_layers = 8\n",
    "    dropout = 0.1\n",
    "    sch_decay = 0.6\n",
    "    device = 'cpu:0'\n",
    "    newpath = './results/full/cost/'\n",
    "    to_predict = 'cost'\n",
    "args = Args()\n",
    "configs = vars(args)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Index Only Scan': 0, 'Index Scan': 1, 'Seq Scan': 2, 'Hash Join': 3, 'Bitmap Index Scan': 4, 'Result': 5, 'Merge Join': 6, 'Limit': 7, 'Aggregate': 8, 'Sort': 9, 'Hash': 10, 'Bitmap Heap Scan': 11, 'Nested Loop': 12, 'Materialize': 13, 'BitmapOr': 14, 'Memoize': 15}\n",
      "{'Actual Total Time': RobustScaler(), 'Plan Rows': RobustScaler(), 'Total Cost': RobustScaler()}\n"
     ]
    }
   ],
   "source": [
    "with open(path.join(ROOT_DIR, 'data', 'workload1', 'statistics.json')) as file:\n",
    "    feature_statistics = json.load(file)\n",
    "encoder = tu.Encoder(feature_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200000, 1, 360]) torch.Size([200000, 20, 20]) torch.Size([200000, 1]) torch.Size([200000, 1])\n"
     ]
    }
   ],
   "source": [
    "files_name = []\n",
    "for wk_item in workloads:\n",
    "    files_name.append(path.join(ROOT_DIR, 'data', 'workload1', wk_item + '_filted.json'))\n",
    "\n",
    "dict_list = tu.Encoder.format_workload(files_name)\n",
    "alldataset = tu.PlanTreeDataSet(dict_list, encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 4 4\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader = tu.get_dataloader(alldataset, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtanji\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20240219_153636-uwknq9vc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tanji/DACE/runs/uwknq9vc' target=\"_blank\">golden-rat-27</a></strong> to <a href='https://wandb.ai/tanji/DACE' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tanji/DACE' target=\"_blank\">https://wandb.ai/tanji/DACE</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tanji/DACE/runs/uwknq9vc' target=\"_blank\">https://wandb.ai/tanji/DACE/runs/uwknq9vc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'accelerator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      4\u001b[0m logger\u001b[38;5;241m.\u001b[39mlog_hyperparams(configs)\n\u001b[0;32m      5\u001b[0m checkpoint_callback \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\n\u001b[0;32m      6\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     dirpath\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ROOT_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      8\u001b[0m     filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDACE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     10\u001b[0m trainer \u001b[38;5;241m=\u001b[39mpl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m---> 11\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[43mconfigs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccelerator\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[0;32m     12\u001b[0m     enable_progress_bar\u001b[38;5;241m=\u001b[39mconfigs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprogress_bar\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     13\u001b[0m     enable_model_summary\u001b[38;5;241m=\u001b[39mconfigs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprogress_bar\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     14\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39mconfigs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     15\u001b[0m     logger\u001b[38;5;241m=\u001b[39mlogger,\n\u001b[0;32m     16\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[checkpoint_callback],\n\u001b[0;32m     17\u001b[0m )\n",
      "\u001b[1;31mKeyError\u001b[0m: 'accelerator'"
     ]
    }
   ],
   "source": [
    "model = tm.SeqFormer(args, input_dim=18, hidden_dim=192, output_dim=1)\n",
    "logger = pl.loggers.WandbLogger(project=\"DACE\")\n",
    "logger.log_hyperparams(args)\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    dirpath=os.path.join(ROOT_DIR, \"checkpoints\"),\n",
    "    filename=\"DACE\",\n",
    ")\n",
    "trainer =pl.Trainer(\n",
    "    accelerator=args.accelerator,\n",
    "    enable_progress_bar=args.progress_bar,\n",
    "    enable_model_summary=args.progress_bar,\n",
    "    max_epochs=args.max_epoch,\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = PLTrainer(accelerator=\"cpu\", max_epochs=50, logger=wandb_logger)\n",
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "result = trainer.test(model, dataloaders=test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
